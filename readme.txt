- Usage
Place LLama models into "pretrained" directory
And then run the UI.py file

Please refer to 'huggingface-llama-recipes' for the further customization

Current code is implemented through Gradio for the prompt prototype but you can customize your code on your own sage.

Environment setup:
Cudatoolkit==11.8
Nvidia driver = 520.61

Further model download:
If you need to download other models from "Meta-llama" Use this access token and user
User: FredrikNLP
Access token: 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

It's allowed to download LLama3.1, 3.2 series
Enjoy!